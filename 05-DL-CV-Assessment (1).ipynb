{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 1s 18us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 14s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize an image from the dataset\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.title('Example Image from Fashion MNIST Dataset')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the X train and X test data\n",
    "x_train_normalized = x_train / 255\n",
    "x_test_normalized = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reshape the X arrays to include a 4th dimension for single channel\n",
    "x_train_reshaped = np.reshape(x_train_normalized, (x_train_normalized.shape[0], 28, 28, 1))\n",
    "x_test_reshaped = np.reshape(x_test_normalized, (x_test_normalized.shape[0], 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train and y_test to one-hot encoded format\n",
    "num_classes = 10  # Number of classes (labels) in the Fashion MNIST dataset\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    # Convolutional layer with 32 filters and kernel size (4,4)\n",
    "    Conv2D(32, (4, 4), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Pooling layer with pool size (2,2)\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flatten layer to convert 2D feature maps into a 1D feature vector\n",
    "    Flatten(),\n",
    "    # Dense layer with 128 neurons and ReLU activation\n",
    "    Dense(128, activation='relu'),\n",
    "    # Final dense layer with 10 neurons (one for each class) and softmax activation\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 25, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 591786 (2.26 MB)\n",
      "Trainable params: 591786 (2.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1500/1500 [==============================] - 17s 10ms/step - loss: 0.4275 - accuracy: 0.8478 - val_loss: 0.3424 - val_accuracy: 0.8752\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.2895 - accuracy: 0.8964 - val_loss: 0.2852 - val_accuracy: 0.8971\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.2464 - accuracy: 0.9106 - val_loss: 0.2796 - val_accuracy: 0.9008\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.2160 - accuracy: 0.9216 - val_loss: 0.2735 - val_accuracy: 0.9053\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1924 - accuracy: 0.9299 - val_loss: 0.2753 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1726 - accuracy: 0.9378 - val_loss: 0.3108 - val_accuracy: 0.8954\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1551 - accuracy: 0.9439 - val_loss: 0.2845 - val_accuracy: 0.9064\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1383 - accuracy: 0.9498 - val_loss: 0.2984 - val_accuracy: 0.9055\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1276 - accuracy: 0.9544 - val_loss: 0.3189 - val_accuracy: 0.9080\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1127 - accuracy: 0.9601 - val_loss: 0.3355 - val_accuracy: 0.9066\n"
     ]
    }
   ],
   "source": [
    "epochs = 10  \n",
    "history = model.fit(x_train_reshaped, y_train_one_hot, epochs=epochs, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for test data\n",
    "y_prob = model.predict(x_test_reshaped)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = np.argmax(y_prob, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3626386821269989\n",
      "Test Accuracy: 0.9042999744415283\n",
      "Accuracy: 0.9043\n",
      "Precision: 0.905732245668213\n",
      "Recall: 0.9043\n",
      "F1-score: 0.9042791082902207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert one-hot encoded y_test back to categorical labels\n",
    "y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "precision = precision_score(y_test_labels, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_labels, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_labels, y_pred, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84      1000\n",
      "           1       1.00      0.97      0.98      1000\n",
      "           2       0.88      0.80      0.83      1000\n",
      "           3       0.88      0.94      0.91      1000\n",
      "           4       0.81      0.89      0.85      1000\n",
      "           5       0.98      0.97      0.98      1000\n",
      "           6       0.73      0.76      0.75      1000\n",
      "           7       0.96      0.96      0.96      1000\n",
      "           8       0.98      0.98      0.98      1000\n",
      "           9       0.95      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.91      0.90      0.90     10000\n",
      "weighted avg       0.91      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test_one_hot, verbose=0)\n",
    "\n",
    "# Predict probabilities for test data\n",
    "y_prob = model.predict(x_test_reshaped)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "# Convert one-hot encoded y_test back to categorical labels\n",
    "y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test_labels, y_pred, digits=2)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
